<%@meta language="R-vignette" content="--------------------------------
  DIRECTIVES FOR R:

  %\VignetteIndexEntry{Introduction to RBi.helpers}
  %\VignetteAuthor{Sebastian Funk}
  %\VignetteKeyword{rbi.helpers}
  %\VignetteKeyword{package}
  %\VignetteKeyword{vignette}
  %\VignetteTangle{FALSE}
  %\VignetteEngine{R.rsp::rsp}
--------------------------------------------------------------------"%>

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

# <%@meta name="title"%>

<%@meta name="author"%> on <%=format(as.Date(Sys.Date()), format="%B %d, %Y")%>

```{R, echo=FALSE}
TRAVIS <- !identical(tolower(Sys.getenv("TRAVIS")), "true")
knitr::opts_chunk$set(purl = TRAVIS)
set.seed(13)
```

[RBi.helpers](https://github.com/sbfnk/RBi.helpers) is collection of helper functions to use with [RBi](https://github.com/libbi/RBi), an R interface to [LibBi](https://github.com/libbi/LibBi), a library for Bayesian Inference.

### Latest Version: _0.3.1_

This vignette builds on the [RBi vignette](https://CRAN.R-project.org/package=rbi/vignettes/introduction.html), applying the higher-level functions contained in **RBi.helpers** to the same model introduced there.
For the lower-level functions to run **LibBi** and read the results, please refer to the documentation and vignette that comes with **RBi**.

# Installation

The **RBi.helpers** package requires `R` (>= 3.2.0) as well as the packages:

- `rbi`
- `data.table`
- `reshape2`
- `lubridate`
- `Matrix`

Most functions also require a working installation of **LibBi**.
Please see the [RBi vignette](https://CRAN.R-project.org/package=rbi/vignettes/introduction.html) for how to get one via homebrew or linuxbrew.

The easiest way to install the latest stable version of **RBi.helpers** is via CRAN. The package name is `rbi.helpers` (all lowercase):

```{r eval=FALSE}
install.packages('rbi.helpers')
```

Alternatively, the current development version can be installed using the `devtools` package

```{R eval=FALSE}
# install.packages("devtools")
library('devtools')
install_github("sbfnk/rbi.helpers")
```

# Loading the package

Use

```{R eval=FALSE}
library('rbi.helpers')
```

```{R echo=FALSE}
suppressPackageStartupMessages(library('rbi.helpers'))
```

to load the package.

# Loading the model and generating a synthetic dataset

These steps are reproduced from the [RBi vignette](https://CRAN.R-project.org/package=rbi/vignettes/introduction.html), where there is more information on the individual steps

```{R}
model_file <- system.file(package="rbi", "SIR.bi") # get full file name from package
SIRmodel <- bi_model(model_file) # load model
set.seed(1001912)
SIRdata <- bi_generate_dataset(SIRmodel, end_time=16*7, noutputs=16)
```

# Adapt the number of particles

In the [RBi vignette](https://CRAN.R-project.org/package=rbi/vignettes/introduction.html), a [stochastic SIR model](https://raw.githubusercontent.com/libbi/RBi/master/inst/SIR.bi) is fitted to simulated data from the same model using particle Markov-chain Monte Carlo with 32 particles.
Given a model and data, how do we know how many particles we need?
This question does not have a simple answer, as the "optimal" number of particles may depend on the state of the Markov chain.
A possible rule-of-thumb is to choose the number of particles such that the variance of the log-likelihood near the mode is approximately one.
This suggests a [strategy](https://darrenjw.wordpress.com/2014/06/08/tuning-particle-mcmc-algorithms/) by which first and approximate location of the mode or mean of the posterior distribution is obtained in a trial run, before the numer of particles is adjusted by monitoring the variance of the log-likelihood while keeping the parameters fixed.
**RBi.helpers** implements the second part of this strategy (adjusting the number of particles at a given location in parameter space) with the `adapt_particles` method.
For the first part (finding the mode), a crude method is to take a fixed number of samples from the prior distribution and choose the one that maximises the posterior.
In **RBi**, this can be achieved with

```{R eval=FALSE}
bi_prior <- sample(proposal="prior", SIRmodel, nsamples=1000, end_time=16*7, nparticles=4, obs=SIRdata, seed=1234)
```

```{R echo=FALSE, eval=TRAVIS}
bi_prior <- rbi::sample(proposal="prior", SIRmodel, nsamples=1000, end_time=16*7, nparticles=4, obs=SIRdata, seed=1234)
```

This runs particle MCMC with the prior distribution as proposal distribution (because `proposal="prior"`), in this case with 4 particles.
In other words, when sampling from the posterior the proposals will be drawn independently from the prior distribution.
Note that we set a seed to make the results reproducible.
It is worth trying the commands with a different seed and seeing the difference to the results obtained below.
The location in parameters of the sampler at the end of the 1000 iterations will give an approximation of the mode of the posterior distribution.
This can then be used to adjust the number of particles using

```{R, eval=TRAVIS}
adapted <- adapt_particles(bi_prior)
```

This will take the last sample of the output file contained in the `libbi` object `bi_prior`, and use it to adjust the number of particles by starting with 1 particle (or a given `min`) and doubling it until the variance of the loglikelihood crosses 1.
The number of particles is then saved in the `adapted` object:

```{R, eval=TRAVIS}
adapted$options$nparticles
```

# Adapt the proposal distribution

Having adjusted the number of particles, the second important information to give the posterior sampler is the proposal distribution.
This can, again, be obtained using a sequence of trial runs, whereby the proposal distribution is sequentially adjusted from previous samples to be proportional to the empirical covariance of the posterior samples.
The way this is implemented in the `adapt_proposal` function in **RBi.helpers** is that the proposal distribution is adjusted to come from a multivariate normal taking into account the covariance of samples obtained so far, until the acceptance rate lies between the given minimum and maximumad.
For example, to adjust the proposal distribution for an acceptance rate between 0.05 and 0.4, we can run:

```{R, eval=TRAVIS}
adapted <- adapt_proposal(adapted, min=0.05, max=0.4)
```

The covariance matrices for parameters and initial conditions are stored in the input file contained in the `libbi` object `adapted`

```{R, eval=TRAVIS}
bi_read(adapted, file="input")
```

# Compute DIC

To compute the [Deviance Information Criterion](https://en.m.wikipedia.org/wiki/Deviance_information_criterion) (DIC), use `DIC`:

```{R, eval=TRAVIS}
posterior <- sample(adapted)
DIC(posterior)
```

This samples from the posterior distribution using the adapted number of particles and proposal distribution and then calculates the DIC.

# Convert between LibBi times and actual times or dates

LibBi uses real-valued times. To convert these to time or date objects for use in R, use the `numeric_to_time` function:

```{R, eval=TRAVIS}
res <- numeric_to_time(posterior, unit="day", origin=as.Date("2018-04-01"))
head(res$Z)
```

The function `time_to_numeric` does the converse, converting R times or dates into numeric values for use by LibBi:

```{R, eval=TRAVIS}
orig <- time_to_numeric(res, unit="day", origin=as.Date("2018-04-01"))
head(orig$Z)
```

# Create inference chains

In combination with the `magrittr` package, the it is possible to construct inference chains more elegantly. For example, to get posterior samples from adapted Metropolis-Hastings including sampled observations, we could have written

```{R eval=FALSE}
library('magrittr')
posterior <- sample(proposal="prior", SIRmodel, nsamples=1000, end_time=16*7, nparticles=4, obs=SIRdata, seed=1234) %>%
  adapt_particles %>%
  adapt_proposal(min=0.05, max=0.4) %>%
  sample(nsamples=5000) %>%
  sample_obs
```
